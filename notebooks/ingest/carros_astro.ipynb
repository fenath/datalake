{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1bbdb911-28de-4588-9951-19fa5d5e2a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.catalog import load_catalog\n",
    "from pyiceberg.schema import Schema\n",
    "from pyiceberg.types import NestedField, StringType\n",
    "from datetime import datetime\n",
    "import polars as pl\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "\n",
    "# -------------------\n",
    "# catálogo\n",
    "# -------------------\n",
    "catalog = load_catalog(\n",
    "    \"dev\",\n",
    "    uri=\"http://rest:8181\",\n",
    "\n",
    "    **{\n",
    "        \"s3.endpoint\": \"http://minio:9000\",\n",
    "        \"s3.access-key-id\": \"minioadmin\",\n",
    "        \"s3.secret-access-key\": \"minioadmin\",\n",
    "        \"s3.path-style-access\": \"true\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# -------------------\n",
    "# s3 / minio\n",
    "# -------------------\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=\"http://minio:9000\",\n",
    "    aws_access_key_id=\"minioadmin\",\n",
    "    aws_secret_access_key=\"minioadmin\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2358b756-7ca6-457f-b9b9-73b147b8a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper para criação de tabelas\n",
    "from pyiceberg.partitioning import PartitionSpec\n",
    "from pyiceberg.transforms import IdentityTransform\n",
    "from pyiceberg.schema import Schema\n",
    "from pyiceberg.types import NestedField\n",
    "from pyiceberg.io.pyarrow import pyarrow_to_schema\n",
    "\n",
    "\n",
    "def build_partition_spec(schema, partition_cols):\n",
    "    # nenhum particionamento\n",
    "    if not partition_cols:\n",
    "        return PartitionSpec()\n",
    "\n",
    "    fields = []\n",
    "\n",
    "    for i, col in enumerate(partition_cols, start=1000):\n",
    "        field = schema.find_field(col)\n",
    "\n",
    "        if field is None:\n",
    "            raise ValueError(f\"Coluna '{col}' não existe no schema\")\n",
    "\n",
    "        fields.append(\n",
    "            PartitionSpec.Field(\n",
    "                source_id=field.field_id,\n",
    "                field_id=i,\n",
    "                transform=IdentityTransform(),\n",
    "                name=col,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return PartitionSpec(*fields)\n",
    "\n",
    "def update_schema(table, arrow_schema):\n",
    "    \"\"\"\n",
    "    Atualiza o schema da tabela Iceberg se houver colunas novas no DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    table : Iceberg table\n",
    "        Tabela a ser verificada/atualizada\n",
    "    arrow_schema : pyarrow.Schema\n",
    "        Schema do DataFrame que será inserido\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True se o schema foi atualizado, False caso contrário\n",
    "    \"\"\" \n",
    "    # Atualiza o schema adicionando as novas colunas\n",
    "    with table.update_schema() as update:\n",
    "        update.union_by_name(arrow_schema)\n",
    "    \n",
    "    print(f\"✔ schema atualizado\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def set_table(\n",
    "    catalog,\n",
    "    table_name: str,\n",
    "    df,\n",
    "    partition_cols=None,\n",
    "    mode=\"append\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Cria ou carrega uma tabela Iceberg e escreve dados nela.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    catalog : Iceberg catalog\n",
    "    table_name : str\n",
    "    df : polars.DataFrame\n",
    "    partition_cols : list[str] | None\n",
    "    mode : 'append' | 'overwrite'\n",
    "    \"\"\"\n",
    "\n",
    "    # garante nomes limpos\n",
    "    df = df.rename(lambda c: c.strip())\n",
    "\n",
    "    arrow_table = df.to_arrow()\n",
    "    arrow_schema = arrow_table.schema\n",
    "\n",
    "    # -------------------\n",
    "    # load or create\n",
    "    # -------------------\n",
    "    try:\n",
    "        table = catalog.load_table(table_name)\n",
    "        update_schema(table, arrow_schema)\n",
    "        print(f\"✔ tabela '{table_name}' carregada\")\n",
    "\n",
    "    except Exception as e:\n",
    "        if \"NoSuchTable\" not in str(type(e)):\n",
    "            raise  # erro real → não cria tabela\n",
    "    \n",
    "        print(f\"⚙ criando tabela '{table_name}'\")\n",
    "    \n",
    "        partition_spec = build_partition_spec(arrow_schema, partition_cols)\n",
    "    \n",
    "        table = catalog.create_table(\n",
    "            identifier=table_name,\n",
    "            schema=arrow_schema,\n",
    "            partition_spec=partition_spec,\n",
    "            properties={\n",
    "                \"write.format.default\": \"parquet\",\n",
    "                \"write.parquet.compression-codec\": \"zstd\",\n",
    "                \"schema.name-mapping.default\": \"true\",\n",
    "            },\n",
    "        )\n",
    "    # -------------------\n",
    "    # write\n",
    "    # -------------------\n",
    "    if mode == \"overwrite\":\n",
    "        table.overwrite(arrow_table)\n",
    "    elif mode == \"append\":\n",
    "        table.append(arrow_table)\n",
    "    elif mode in (\"reset\"):\n",
    "        print(\"⚠ full reset da tabela\")\n",
    "        table.delete(\"true\")   # remove todos datafiles ativos\n",
    "        table.append(arrow_table)\n",
    "\n",
    "    print(f\"✔ dados gravados ({mode})\")\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1a5f3daa-0266-4c4d-9afc-cc5b03d7782e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not determine dtype for column 9, falling back to string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ schema atualizado\n",
      "✔ tabela 'bronze.raw_excel' carregada\n",
      "⚠ full reset da tabela\n",
      "✔ dados gravados (reset)\n",
      "✔ RAW ingestão concluída\n"
     ]
    }
   ],
   "source": [
    "## RAW\n",
    "\n",
    "\n",
    "bucket = \"raw\"\n",
    "key = \"carros_astro/ENTRADAS E SAÍDAS ASTRO AUTOMÓVEIS.xlsx\"\n",
    "\n",
    "response = s3.get_object(Bucket=bucket, Key=key)\n",
    "buffer = BytesIO(response[\"Body\"].read())\n",
    "\n",
    "# -------------------\n",
    "# leitura excel\n",
    "# -------------------\n",
    "df = pl.read_excel(buffer, has_header=False)\n",
    "\n",
    "# transforma tudo em string (RAW tolerante)\n",
    "df = df.with_columns(pl.all().cast(pl.Utf8))\n",
    "\n",
    "# adiciona metadata de ingestão\n",
    "df = df.with_columns(\n",
    "    pl.lit(key).alias(\"_source_file\"),\n",
    "    pl.lit(datetime.utcnow().isoformat()).alias(\"_ingestion_time\"),\n",
    ")\n",
    "\n",
    "arrow_table = df.to_arrow()\n",
    "set_table(catalog, \"bronze.raw_excel\", df, mode=\"reset\")\n",
    "\n",
    "\n",
    "print(\"✔ RAW ingestão concluída\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b2490f56-60a4-4ded-a685-b694460928a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DATA ENTRADA',\n",
       " 'NOTA COMPRA',\n",
       " 'VEÍCULO',\n",
       " 'PLACA',\n",
       " 'VALOR ENTRADA',\n",
       " 'NOTA SAÍDA',\n",
       " 'DATA SAÍDA',\n",
       " 'VALOR VENDA',\n",
       " '_source_file',\n",
       " '_ingestion_time',\n",
       " 'ano_raw',\n",
       " 'is_label',\n",
       " 'mes_raw',\n",
       " 'sequencia',\n",
       " 'vl_entrada',\n",
       " 'vl_saida']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = catalog.load_table(\"bronze.raw_excel\")\n",
    "\n",
    "df = pl.from_arrow(table.scan().to_arrow())\n",
    "anos = df[\"column_4\"].str.to_integer(strict=False).unique().to_list()\n",
    "first_ano = [a for a in anos if a is not None][0]-1\n",
    "\n",
    "df = df.with_columns(\n",
    "    ano_raw = (\n",
    "        pl.col(\"column_4\")\n",
    "        .str.to_integer(strict=False)\n",
    "        .forward_fill().fill_null(first_ano)\n",
    "    ),\n",
    "    is_label = (\n",
    "        pl.col(\"column_4\").is_not_null() &\n",
    "        pl.col(\"column_1\").is_null()\n",
    "    )\n",
    ")\n",
    "\n",
    "df = df.with_columns(\n",
    "    mes_raw = pl.when(\n",
    "        pl.col(\"is_label\")\n",
    "    ).then(pl.col('column_4')).otherwise(None)\n",
    "    .forward_fill()\n",
    ")\n",
    "\n",
    "column_labels = list(df.row(0))\n",
    "columns = df.columns\n",
    "mapping = { col: column_labels[idx].strip()\n",
    "           for idx,col in enumerate(columns)\n",
    "           if col.startswith('column') \n",
    "           and column_labels[idx] is not None}\n",
    "\n",
    "def cast_date(column_name):\n",
    "    col = pl.col(column_name)\n",
    "\n",
    "    serial = (\n",
    "        pl.date(1899, 12, 30) +\n",
    "        pl.duration(\n",
    "            days=col.cast(pl.Float64, strict=False)\n",
    "            .cast(pl.Int64, strict=False)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    text_date = col.str.strptime(\n",
    "        pl.Date,\n",
    "        \"%d/%m/%Y\",\n",
    "        strict=False\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        pl.coalesce([serial, text_date])\n",
    "        .alias(column_name)\n",
    "    )\n",
    "\n",
    "def cast_currency(col_name):\n",
    "    return (\n",
    "        pl.col(col_name).cast(pl.Float32).alias(col_name)\n",
    "    )\n",
    "\n",
    "df = df.rename(mapping)\n",
    "df = df.drop_nulls(subset=[\"column_1\"])\n",
    "\n",
    "df = df.with_columns(\n",
    "    cast_date(\"DATA SAÍDA\"),\n",
    "    cast_date(\"DATA ENTRADA\"),\n",
    "    pl.col('column_1').cast(pl.Int64).alias(\"sequencia\"),\n",
    "    pl.col('VALOR ENTRADA').cast(pl.Float32, strict=False).alias(\"vl_entrada\"),\n",
    "    pl.col('VALOR VENDA').cast(pl.Float32, strict=False).alias(\"vl_saida\"),\n",
    ")\n",
    "df = df.drop([\"column_10\", 'column_1'])\n",
    "\n",
    "df\n",
    "\n",
    "df.filter(pl.col(\"PLACA\") == \"ODF-1H32\")\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "70fa70e8-f8e9-469e-9b62-80a8d84e8af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ schema atualizado\n",
      "✔ tabela 'silver.carros_astro' carregada\n",
      "⚠ full reset da tabela\n",
      "✔ dados gravados (reset)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "carros_astro(\n",
       "  1: sequencia: optional long,\n",
       "  2: VEÍCULO: optional string,\n",
       "  3: PLACA: optional string,\n",
       "  4: DATA ENTRADA: optional date,\n",
       "  5: DATA SAÍDA: optional date,\n",
       "  6: vl_entrada: optional float,\n",
       "  7: vl_saida: optional float,\n",
       "  8: ano_raw: optional long,\n",
       "  9: mes_raw: optional string,\n",
       "  10: _source_file: optional string,\n",
       "  11: _ingestion_time: optional string,\n",
       "  12: NOTA SAÍDA: optional string,\n",
       "  13: NOTA COMPRA: optional string\n",
       "),\n",
       "partition by: [],\n",
       "sort order: [],\n",
       "snapshot: Operation.APPEND: id=6070894803919287373, parent_id=2979075849402979294, schema_id=1"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Save to silver\n",
    "\n",
    "silver_df = df.select([\n",
    "    \"sequencia\",\n",
    "    \"VEÍCULO\",\n",
    "    \"PLACA\",\n",
    "    \"DATA ENTRADA\",\n",
    "    \"DATA SAÍDA\",\n",
    "    'NOTA SAÍDA',\n",
    "    'NOTA COMPRA',\n",
    "    \"vl_entrada\",\n",
    "    \"vl_saida\",\n",
    "    \"ano_raw\",\n",
    "    \"mes_raw\",\n",
    "    \"_source_file\",\n",
    "    \"_ingestion_time\",\n",
    "])\n",
    "\n",
    "set_table(\n",
    "    catalog,\n",
    "    \"silver.carros_astro\",\n",
    "    silver_df,\n",
    "    mode=\"reset\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92380a4-393a-4af3-a899-1482f0f0d2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c8e67a97-8ee8-4481-81aa-b9ed3936d36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (100, 4)\n",
      "┌────────────────┬──────────┬─────────────────────────────────┬─────────────────────────────────┐\n",
      "│ data_transacao ┆ valor    ┆ descricao                       ┆ source_file                     │\n",
      "│ ---            ┆ ---      ┆ ---                             ┆ ---                             │\n",
      "│ date           ┆ f64      ┆ str                             ┆ str                             │\n",
      "╞════════════════╪══════════╪═════════════════════════════════╪═════════════════════════════════╡\n",
      "│ 2025-10-02     ┆ 79.79    ┆ Portal da Bahia                 ┆ s3a://raw/nubank/Nubank_2025-1… │\n",
      "│ 2025-10-02     ┆ 29.9     ┆ Pizza Hut Shopping Par          ┆ s3a://raw/nubank/Nubank_2025-1… │\n",
      "│ 2025-10-02     ┆ 6.99     ┆ Ponto Cultural                  ┆ s3a://raw/nubank/Nubank_2025-1… │\n",
      "│ 2025-10-01     ┆ 111.78   ┆ Hotel At Booking.Com            ┆ s3a://raw/nubank/Nubank_2025-1… │\n",
      "│ 2025-10-01     ┆ 12.9     ┆ Kfc Shop Paralela Ba            ┆ s3a://raw/nubank/Nubank_2025-1… │\n",
      "│ …              ┆ …        ┆ …                               ┆ …                               │\n",
      "│ 2025-09-03     ┆ -4896.63 ┆ Pagamento recebido              ┆ s3a://raw/nubank/Nubank_2025-1… │\n",
      "│ 2025-09-03     ┆ 135.56   ┆ Gol Linhas A*Abcfyx013 - Parce… ┆ s3a://raw/nubank/Nubank_2025-1… │\n",
      "│ 2025-09-03     ┆ 433.92   ┆ Azul Linhas Nn6u9a - Parcela 5… ┆ s3a://raw/nubank/Nubank_2025-1… │\n",
      "│ 2025-09-03     ┆ 100.9    ┆ Gaertner Pereira Produ - Parce… ┆ s3a://raw/nubank/Nubank_2025-1… │\n",
      "│ 2025-09-02     ┆ 20.64    ┆ Cafe Dois Irmaos                ┆ s3a://raw/nubank/Nubank_2025-0… │\n",
      "└────────────────┴──────────┴─────────────────────────────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "tbl = catalog.load_table(\"silver.nubank_clean\")\n",
    "\n",
    "df = pl.from_arrow(tbl.scan().to_arrow())\n",
    "print(df.head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbd3e8a-ca3f-4da5-a60d-9e1f7d9e0c36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
